\section{Complex Simulations\label{sec:complex-simulations}}
  Complex simulations are one of the primary fields whereby dynamic spatial data is utilised. Many of these simulations model the behaviour of a large number of mobile agents that interact with neighbouring agents and the local environment. These simulations are regularly utilised in high-performance scenarios whereby improvements to performance allow models to increase in both scale and complexity.
  
  The following sections provide some examples of complex simulations which stand to benefit from a dynamic spatial data-structure, discussing the current techniques used in their operation.

  \subsection{\glsentrylong{sph}\label{sec:complex-sph}}
\begin{figure}
  \begin{centering}
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{\string"../resources/sph-MattLeach/4\string".jpg}
  \par\end{centering}
  \protect\caption[Simulation of blood flowing over a hand which was generated using \gls{sph}.]{\label{fig:sph}Simulation of blood flowing over a hand which was generated using \gls{sph}.\\ \em{Used with permission of Matthew Leach, University of Sheffield}}
\end{figure}
    \gls{sph} is a computational technique used for the simulation of fluid dynamics. The technique was first developed in 1977 at the Institute of Astronomy in Cambridge UK, applying the Newtonian equations for particles in order to solve astrophysics problems \cite{GM77,Luc77}. Since then \gls{sph} has been further applied to Astrophysics, alongside other fields including: Ballistics, Graphics, Oceanography, Solid mechanics \& Volcanology \cite{Mon12}. Figure \ref{fig:sph} shows an example of \gls{sph} being used to simulate blood motion.
    
    \gls{sph} decomposes a fluid into a discrete set of particles. A variable `smoothing length' is used, such that any particle's properties can be calculated from the neighbouring particles that reside within that range of the desired particle. Each particle's contribution to the calculation of a property is weighted according to their distance from the particle that's properties are being computed. A Gaussian function or cubic spline is often used to calculate this weight.
    
    In particular, the representation of particles within fluids, which in many cases consists of thousands or more particles, is where \gls{sph} can benefit from improvements to the handling of dynamic spatial data. Fluids are inherently mobile, therefore it can be seen that their constituent particles are similarly mobile. \gls{sph} requires that particles sample from other nearby particles, therefore this also shows that \gls{sph} would benefit from a dynamic spatial data-structure capable of neighbourhood searches. 
    
    Due to the high numbers of particles that are following the same rules, this makes \gls{sph} ideal for \gls{gpu} computation. With the advent of \gls{gpgpu} software, many \gls{sph} simulations have been accelerated to real-time, and some researchers are now taking advantage of multi-GPU implementations to achieve even larger simulations \cite{DC*13}.
    
    Harada et al's early \gls{sph} \gls{gpu} implementation, simply stored particles identifiers inside a bucket texture \cite{hkk07}. More recent implementations using \gls{gpgpu} techniques utilise spatial subdivision. The simplest of which is a loose uniform grid, whereby the environment is partitioned into a regular grid. Each particle is then stored into the bin within which it's location resides. This structure is however rebuilt each time step due to particle motion \cite{Gre10}. The performance of this has been further improved through the utilisation of space-filling curves \cite{GS*10}, these are explained in more depth in section \ref{sub:spatial-partitioning}.
  
  \subsection{Pedestrian Modelling\label{sub:ped-modelling}}
    Pedestrian \& crowd modelling are concerned with the replication of the behaviour of pedestrians in reaction to each other and the environment. The particular field can be separated in two disciplines: accurate (data driven) \& aesthetic (visually driven). Whilst these two fields are concerned with different properties for evaluation and performance considerations, they both involve the replication of natural pedestrian behaviour.
    
    Data driven crowd modelling is used by the fields of social science and engineering to validate architecture designs and evacuation protocols. These models are therefore concerned with accurately replicating pedestrian behaviour, identifying emergent phenomenas in real crowds and seeking to reproduce both high and low level behaviours within their virtual crowds.
    
    Visually driven crowd modelling is used by game developers and animators to produce realistic crowd behaviour. Whilst less concern is taken with regard to the accuracy of the crowd behaviour, it is imperative that the behaviour appears natural to an untrained viewer alongside other graphical elements within the environment.

    Common to both of these fields is the need for performant crowd simulations. Accuracy driven implementations are expected to run faster than real-time to allow hundreds of simulations to be completed to account for stochastic behaviours and to potentially review many designs. Whereas visually driven implementations require the algorithms controlling crowds to run concurrently in real-time with the various other methods required to make a game function. The crowd included in a game must be light-weight enough that it does not impact the performance of the game. This has previously been achieved by reducing the size of crowds, simpler rules of motion could also be used to benefit performance \cite{Fau12}.
    
    There are three scopes of model that are used for simulating crowds. \gls{ca} were first defined by Von Neumann in 1951 \cite{Neu51} as a means for generalising biological systems. Within a \gls{ca} the environment is discretised into a regular grid. Each time-step, every cell within the grid decides its new state based on the state of it's neighbouring cells. \gls{ca} have been applied to crowd dynamics and shown to reproduce much empirical data \cite{PT*02,ZZL09}.
    
    Fluids dynamics has also been used as a means for representing crowds of pedestrians. Various researchers have proposed that dense crowds behave similarly to a fluid or gas \cite{Hen71,Bra93}. These models present a macroscopic view, using partial differential equations to calculate the changes to density and velocity of a crowd over time. Treuille et al developed a model that builds on fluid dynamics, this allowed the removal of explicit collision avoidance \cite{TCP06}.
    
    In 1995 Helbing and Molnar proposed the theory of social forces \cite{HM95}. This theory, whilst influenced by existing gas-kinetic models, contends that the motion of pedestrians can be described as though they are affected by `social forces' in a continuous space. Each pedestrian is affected by 4 forces: the desire the reach a specific destination; the desire to remain at a specific distance from other pedestrians; the desire to keep a certain distance from obstacles (such as walls); and the occasional attraction to other pedestrians (e.g. friends) and objects (e.g. shop windows). In addition to regular crowd simulation \cite{ST05}, this theory has been widely used for evacuation \cite{GH08} and detection of suspicious behaviour \cite{MOS09}. Helbing et al also later extended the model to account for behaviours present in panic scenarios \cite{HFV00}.
    
    Of the three scopes of modelling available for crowds, the microscopic nature of the continuous social forces model provides the highest fidelity. Within a social forces model, it should be apparent that pedestrians are essentially spatial agents that smoothly avoid collisions under regular circumstances. For pedestrian agents to handle collision avoidance, it becomes necessary for them to access data related to neighbouring pedestrians. This, coupled with their mobile nature, makes them suited to benefit from a dynamic spatial data-structure.

    Microscopic pedestrian models, similar to \gls{sph}, also often use spatial partitioning to place agents into dynamic bins. This stems from Reynolds original `flocking' paper which paved the road for much of the early pedestrian simulations \cite{Rey87}. There are however more complex solutions, such as the the Multi-Agent Navigation Graph, developed by Sud et al \cite{SA*08}. This technique utilises first and second order voronoi diagrams to identify the clearance between agents, however it still requires full reconstructions each iteration.

  \subsection{Traffic\label{sub:traffic-modelling}}
    Traffic modelling concerns the replication of the behaviour of vehicles on the road network, in order to pre-empt the effect that network changes and events will have on traffic. There is also the wider field of multi-modal transport modelling that seeks to combine traffic, pedestrian, train and other models of supplementary means of transport towards a unified model of transport systems \cite{CF*03}. However this section will focus on traffic modelling, as pedestrian modelling has been covered above. %The techniques used in the implementation of other transport models are likely to be analogous to either traffic or pedestrian models.
    
    Whilst existing traffic models are often concerned with models within counties of specific areas and roads, there is always demand for increasing performance which would permit models to be executed more frequently or at a greater scale. For example, within the UK, local authorities and Highways England both utilise various traffic models for evaluation of traffic within their jurisdictions \cite{NEYH_MODELs}. %There has also been interest in combining these county level models to produce a national level model, however this would further increase computational requirements.%unsubstatiated
    
    There are several approaches to traffic modelling: macroscopic, mesoscopic, microscopic and hybrid techniques \cite{KH09}. The macro, meso and micro techniques are each concerned with modelling traffic at a different levels of detail. Macro is concerned with modelling traffic on a per-road basis, meso is concerned with traffic in a grouped or platoon of vehicles basis, whereas micro is concerned with modelling individual vehicle interaction. As the modelled agent becomes smaller (roads, groups, vehicles), more agents must be simulated, leading to increased fidelity and requiring more computational intensity. Additionally the hybrid approach, seeks to utilise aspects of microscopic models to enhance macroscopic models, whilst avoiding the additional computational intensity required of microscopic models. 
    
    Whether the operations are occurring for each road (macroscopic) or each vehicle (microscopic), the uniform nature between agents makes them ideal for \gls{gpu} acceleration. Of these techniques, microscopic simulation requires intense computation and simulates many mobile agents (vehicles), therefore it is a suitable candidate to benefit from a dynamic spatial data-structure.
     
    There are tens of available tools for traffic modelling (e.g. AIMSUN \cite{AIMSUN}, Saturn \cite{SATURN} \& VISSIM \cite{VISSIM}), however of those available most models were initially developed several decades ago. As such they are primarily macroscopic (due to the available computational power at the time not making microscopic simulation feasible). The open-source microscopic traffic model: Simulation of Urban MObility (SUMO) currently represents lanes as vectors, whereby each element is a vehicle \cite{SUMO}. Whilst this is intuitive due to the nature of cars being constrained to a graph, this doesn't align vehicles with other vehicles in neighbouring lanes or similar. %It is worth considering whether those locations on a graph could be transformed to spatial coordinates, with the use of a neighbourhood search to identify visible vehicles.%Speculative
    
  \subsection{General Approaches\label{sec:complex-general}}
    Outside of specific models, there are also frameworks and toolkits that ease the development of agent based simulations for researchers unfamiliar with advanced programming concepts. Many of these offer functionality for handling dynamic and continuous spatial data which can be utilised to implement the models described in the above subsections.
    
    Whilst these frameworks are often capable of representing simulations from all the preceding subsections, their concern lies with providing an intuitive interface for users to develop models with. This creates a trade-off whereby generality is gained at the cost of domain-specific optimisations. These frameworks provide an alternate perspective, from which to consider the value of any research which may benefit them, whether a dynamic spatial data-structure would have a simple enough interface and generality to be applicable for their users.
    
    There are many agent based modelling frameworks (NetLogo \cite{NETLOGO}, Swarm \cite{SWARM}, JACK \cite{JACK}, FLAME \cite{KR*10}, etc). Whilst these utilise an array of languages, the majority are \gls{cpu} constrained. More recently FLAMEGPU has provided a \gls{gpgpu} agent based framework, allowing amateur programmers to utilise \gls{gpu} computation \cite{KR*10}. The FLAMEGPU framework currently handles spatial data using the same spatial partitioning method found in \gls{sph}, whereby spatially located agent messages are partitioned into uniform bins every time-step allowing neighbourhood searches.

    Currently most existing agent modelling frameworks target \gls{cpu} implementations. The scalability of \gls{gpgpu} has been shown \cite{DLR07} and this has catalysed the growth of \gls{gpu} computation. Therefore it is clear that improvements to techniques for working with spatial data on \glspl{gpu} will become more beneficial over time.
    
  \subsection{Summary}
    This section has shown the breadth of fields whereby dynamic spatial data is handled during complex simulations, and how many of these have started to adopt the use of GPU computation within the past decade to boost performance. It has also detailed some existing techniques used by these implementations, for handling spatial data, identifying the one known data structure used by them for dynamic spatial data. This provides confidence that an improvement to the parallel handling of dynamic spatial data would be capable of impacting a wide audience.